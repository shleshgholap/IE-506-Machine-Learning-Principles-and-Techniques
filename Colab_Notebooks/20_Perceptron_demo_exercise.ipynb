{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"brdp-ulnZ_YL"},"outputs":[],"source":["#import the required packages\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import random\n","np.random.seed(1000) #seed the random number generator for repeatability "]},{"cell_type":"markdown","metadata":{"id":"vAu3LGDUZ_YX"},"source":["Python modules required for plotting the data points and the hyperplane"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AilS2PKHZ_YZ"},"outputs":[],"source":["def Plot_datapoints(p1,q1,p2,q2):\n","    plt.scatter(p1,q1)\n","    plt.scatter(p2,q2)\n","    plt.grid(b = True, which = 'both')\n","    plt.xlabel(\"x coordinate\")\n","    plt.ylabel(\"y coordinate\")\n","    plt.title(\"Data\")\n","    plt.show()\n","\n","def Plot_Classifier_with_bias(data, w):\n","    x_points=[]\n","    for i in range(len(data)):\n","        x_points.append(data[i][0][0])\n","    maximum = max(x_points)\n","    minimum = min(x_points)\n","    points = []\n","    x_points = np.linspace(minimum,maximum,1000)\n","    for i in range(len(x_points)):\n","        points.append((-w[0]*x_points[i]-w[2])/w[1])\n","\n","    plt.plot(x_points,points,color='black')"]},{"cell_type":"markdown","metadata":{"id":"vql8NzsvZ_Ya"},"source":["Python module used for perceptron's prediction rule"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8gkkKE0FZ_Yb"},"outputs":[],"source":["def prediction(w, x):\n","    #Write code to return a prediction of +1 or -1 according to the perceptron prediction rule "]},{"cell_type":"markdown","metadata":{"id":"KLGD6SOHZ_Yc"},"source":["Python module used for updating the weights of Perceptron"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sePSxAF-Z_Yc"},"outputs":[],"source":["def update_weights(weight, y_label, x_feature, y_pred, misclass):\n","    #write code to update weight and add 1 to misclass if the perceptron misclassifies x_feature\n","    \n","    return weight , misclass"]},{"cell_type":"markdown","metadata":{"id":"XKVatuyuZ_Ye"},"source":["Python module used for Perceptron training"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oNMu1schZ_Ye"},"outputs":[],"source":["def perceptron_training(data):\n","    \n","    w =np.random.randn()  # randomly generating w\n","    flag=0\n","    mistakes = 0\n","    epochs=0\n","\n","    while flag==0 and epochs<50:   # until mistakes are not zero or number of epochs reach 50\n","        mistakes=0\n","        \n","        #we visualize the hyperplane and data points each time to check for progress\n","        Plot_Classifier_with_bias(data, w)\n","         \n","        Plot_datapoints(x1,y1,x2,y2)\n","        #If you wish to distinguish the current point from other data points ...\n","        #write code within the for loop to showcase the point under consideration\n","\n","        for i in range(len(data)):\n","            x = data[i][0]\n","            x = np.concatenate((x,np.ones(1)),axis = 0)\n","            y_hat = prediction(w, x)\n","            \n","            y = data[i][1]\n","            \n","            w , mistakes= update_weights(w, y, x, y_hat, mistakes)\n","\n","        epochs=epochs+1\n","        if mistakes==0:\n","            flag=1             \n","    return w, mistakes"]},{"cell_type":"markdown","metadata":{"id":"NIPQUaMQZ_Yg"},"source":["Data Creation and Visualization"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VuGYOADKZ_Yg"},"outputs":[],"source":["# Data creation, plot the data, and train perceptron\n","\n","#Create 1000 points from a two-dimensionsal normal distribution with mean [4 ,4] and variance [[0.5, 1], [1,0.5]]\n","#Assign the points to data1\n","#data1 = ???\n","\n","\n","#Create 1000 points from a two-dimensionsal normal distribution with mean [-3 ,-3] and variance [[0.5, 0], [0,0.5]]\n","#Assign the points to data2\n","#data2 = ???\n","\n","#We will the data points by plotting \n","x1 = []\n","y1 = []\n","x2 = []\n","y2 = []\n","for i in range(len(data1)):\n","    x1.append(data1[i][0])\n","    y1.append(data1[i][1])\n","    x2.append(data2[i][0])\n","    y2.append(data2[i][1])\n","\n","Plot_datapoints(x1,y1,x2,y2) #This function is available below\n","#Note that the purpose of x1,y1,x2,y2 is required only for plotting \n"]},{"cell_type":"markdown","metadata":{"id":"RDsloQehZ_Yh"},"source":["Label the data points, shuffle them and train perceptron"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WiPsNCyLZ_Yh"},"outputs":[],"source":["#Let us put points in data1 and data2 in a single array called data and attach labels to them\n","data = []\n","for i in range(len(data1)):\n","    data.append((data1[i],1))\n","\n","for i in range(len(data2)):\n","    data.append((data2[i],-1))\n","    \n","#We will shuffle the data (Think why should we do this?)\n","random.shuffle(data)\n","\n","\n","#Train a perceptron on data, get the optimal w as w_star and the number of mistakes \n","w_star,mistakes=perceptron_training(data)   \n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"t5DMR-NDZ_Yj"},"source":["Print the number of mistakes and the optimal weights"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_nG_C5LHZ_Yj"},"outputs":[],"source":["#print the number of mistakes\n","print(mistakes)\n","\n","#print the optimal w \n","print(w_star)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"y0TpRJHwZ_Yk"},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.5"},"colab":{"provenance":[{"file_id":"18cIO7CY7r3mYXmDEcLIrpKQkkzAgoYIc","timestamp":1677912995905}]}},"nbformat":4,"nbformat_minor":0}